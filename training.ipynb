{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d826d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Torch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d341997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './data_spectrograms/'\n",
    "image_dir = './data_spectrograms/'\n",
    "image_paths = []\n",
    "\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_paths.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"Found {len(image_paths)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d2d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=30):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def cleanup_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSpectrogramDataset(Dataset):\n",
    "    def __init__(self, root_dir, annotation_file=None, transform=None, image_size=(224, 224)):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.classes = sorted([d.name for d in self.root_dir.iterdir() if d.is_dir()])\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "\n",
    "        self.samples = []\n",
    "\n",
    "        if annotation_file:\n",
    "            # ✅ Read file list and resolve each path\n",
    "            with open(annotation_file, 'r') as f:\n",
    "                listed_files = [ln.strip() for ln in f if ln.strip()]\n",
    "\n",
    "            for rel_path in listed_files:\n",
    "                rel_path = rel_path.replace(\"\\\\\", \"/\")  # normalize for Windows\n",
    "                cls_name = rel_path.split('/')[0]       # first part = class folder\n",
    "                if cls_name not in self.class_to_idx:\n",
    "                    print(f\"⚠️ Skipping {rel_path} (unknown class '{cls_name}')\")\n",
    "                    continue\n",
    "\n",
    "                full_path = self.root_dir / rel_path\n",
    "                if full_path.exists():\n",
    "                    self.samples.append((str(full_path), self.class_to_idx[cls_name]))\n",
    "                else:\n",
    "                    print(f\"⚠️ Missing file: {full_path}\")\n",
    "        else:\n",
    "            # No annotation file → just take all PNGs\n",
    "            for cls in self.classes:\n",
    "                for full in (self.root_dir / cls).glob(\"*.png\"):\n",
    "                    self.samples.append((str(full), self.class_to_idx[cls]))\n",
    "\n",
    "        if len(self.samples) == 0:\n",
    "            raise ValueError(f\"No spectrogram samples found in {root_dir} with given annotation file.\")\n",
    "\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a38b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transforms = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(112, scale=(0.8, 1.0)),  # Random crop (time/freq region)\n",
    "#     transforms.RandomApply([\n",
    "#         transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1)\n",
    "#     ], p=0.5),\n",
    "#     transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),  # Small shift in time/freq\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "# ])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Validation transforms (no augmentation)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51407a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = './data_spectrograms/'\n",
    "TRAIN_LIST = './data_splits/train.txt'\n",
    "VAL_LIST   = './data_splits/val.txt'\n",
    "TEST_LIST  = './data_splits/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets once\n",
    "train_ds = CustomSpectrogramDataset(DATA_ROOT, TRAIN_LIST, transform=train_transforms)\n",
    "val_ds = CustomSpectrogramDataset(DATA_ROOT, VAL_LIST, transform=val_transforms)\n",
    "test_ds = CustomSpectrogramDataset(DATA_ROOT, TEST_LIST, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c978df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img_tensor):\n",
    "    img = img_tensor.numpy().transpose((1, 2, 0))\n",
    "    img = img * 0.5 + 0.5  # unnormalize\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Pick a random sample\n",
    "sample_idx = random.randint(0, len(train_ds) - 1)\n",
    "image, label = train_ds[sample_idx]\n",
    "\n",
    "# Get class name (if available)\n",
    "class_name = [k for k, v in train_ds.class_to_idx.items() if v == label.item()][0]\n",
    "\n",
    "print(f\"Class label: {label.item()} ({class_name})\")\n",
    "imshow(image)\n",
    "plt.title(f\"Sample from train_ds - Class: {class_name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe83a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_parameters(model, model_name=\"Model\"):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\n--- {model_name} Parameters ---\")\n",
    "    print(f\"Total Parameters:     {total_params:,}\")\n",
    "    print(f\"Trainable Parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model factory functions\n",
    "def get_teacher(num_classes=6, pretrained=True):\n",
    "    try:\n",
    "        if pretrained:\n",
    "            teacher = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        else:\n",
    "            teacher = models.resnet50(weights=None)\n",
    "    except Exception as e:\n",
    "        print('Warning: could not load ResNet50 pretrained weights:', e)\n",
    "        teacher = models.resnet50(weights=None)\n",
    "    teacher.fc = nn.Linear(teacher.fc.in_features, num_classes)\n",
    "    return teacher\n",
    "\n",
    "def get_student(num_classes=6, pretrained=True):\n",
    "    try:\n",
    "        if pretrained:\n",
    "            student = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "        else:\n",
    "            student = models.mobilenet_v2(weights=None)\n",
    "    except Exception as e:\n",
    "        print('Warning: could not load MobileNetV2 pretrained weights:', e)\n",
    "        student = models.mobilenet_v2(weights=None)\n",
    "    student.classifier[1] = nn.Linear(student.last_channel, num_classes)\n",
    "    return student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbed9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher finetuning\n",
    "def finetune_teacher(teacher, train_loader, val_loader, device, epochs=15, lr=1e-4, save_path=None):\n",
    "    \"\"\"Memory-efficient teacher finetuning with reduced epochs\"\"\"\n",
    "    teacher = teacher.to(device)\n",
    "    teacher.train()\n",
    "    optimizer = torch.optim.Adam(teacher.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_acc = 0.0\n",
    "    best_state = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        teacher.train()\n",
    "        running_loss = 0.0\n",
    "        total = 0; correct = 0\n",
    "        \n",
    "        for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
    "            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                outs = teacher(imgs)\n",
    "                loss = criterion(outs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            \n",
    "            # Memory cleanup every 20 batches\n",
    "            if batch_idx % 20 == 0:\n",
    "                del imgs, labels, outs\n",
    "                cleanup_memory()\n",
    "\n",
    "        avg_train_loss = running_loss / max(1, len(train_loader))\n",
    "        train_acc = 100.*correct/total if total>0 else 0.0\n",
    "\n",
    "        # Validation\n",
    "        teacher.eval()\n",
    "        val_loss = 0.0; total=0; correct=0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                \n",
    "                with autocast():\n",
    "                    outs = teacher(imgs)\n",
    "                    loss = criterion(outs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outs,1)\n",
    "                total += labels.size(0)\n",
    "                correct += preds.eq(labels).sum().item()\n",
    "                \n",
    "                del imgs, labels, outs\n",
    "                \n",
    "        avg_val_loss = val_loss / max(1, len(val_loader))\n",
    "        val_acc = 100.*correct/total if total>0 else 0.0\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "        if epoch % 10 == 0: \n",
    "            print(f'Epoch {epoch+1}/{epochs} - train_loss: {avg_train_loss:.4f} train_acc: {train_acc:.2f}% - val_loss: {avg_val_loss:.4f} val_acc: {val_acc:.2f}%')\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_state = copy.deepcopy(teacher.state_dict())\n",
    "            if save_path:\n",
    "                torch.save(best_state, save_path)\n",
    "\n",
    "        cleanup_memory()\n",
    "\n",
    "    if best_state is not None:\n",
    "        teacher.load_state_dict(best_state)\n",
    "    teacher.eval()\n",
    "    cleanup_memory()\n",
    "    return teacher, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf67bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowledge distillation training\n",
    "def train_student_kd(\n",
    "    teacher, student, train_loader, val_loader, device,\n",
    "    epochs=30, lr=1e-4, alpha=0.7, temperature=4.0,\n",
    "    save_path='./student_best.pth'\n",
    "):\n",
    "    \"\"\"Ultra memory-efficient knowledge distillation training\"\"\"\n",
    "    # Move models to device\n",
    "    teacher.to(device)\n",
    "    student.to(device)\n",
    "    teacher.eval()  # Keep teacher in eval mode\n",
    "    \n",
    "    # Freeze teacher completely to save memory\n",
    "    for param in teacher.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    optimizer = torch.optim.Adam(student.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    history = {\n",
    "        'train_ce_loss': [], 'train_mse_loss': [], 'train_total_loss': [],\n",
    "        'val_ce_loss': [], 'val_mse_loss': [], 'val_total_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    print(f\"Training with temperature={temperature}, alpha={alpha} (KD weight)\")\n",
    "    print(\"Using ultra memory-efficient KD\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ==== TRAIN ====\n",
    "        student.train()\n",
    "        ce_sum, mse_sum, total_sum = 0.0, 0.0, 0.0\n",
    "        \n",
    "        for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
    "            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "            # Get teacher outputs (no gradients needed)\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher(imgs).detach()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                student_outputs = student(imgs)\n",
    "\n",
    "                # Calculate losses\n",
    "                ce_loss = F.cross_entropy(student_outputs, labels)\n",
    "                \n",
    "                # mse losses\n",
    "                teacher_soft = F.softmax(teacher_outputs / temperature, dim=1)\n",
    "                student_soft = F.softmax(student_outputs / temperature, dim=1)\n",
    "                mse_loss = F.mse_loss(student_soft, teacher_soft) * (temperature ** 2)\n",
    "                \n",
    "                # Combined loss\n",
    "                total_loss = alpha * mse_loss + (1 - alpha) * ce_loss\n",
    "\n",
    "            scaler.scale(total_loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Track losses\n",
    "            ce_sum += ce_loss.item()\n",
    "            mse_sum += mse_loss.item()\n",
    "            total_sum += total_loss.item()\n",
    "\n",
    "            # Aggressive memory cleanup every 10 batches\n",
    "            if batch_idx % 10 == 0:\n",
    "                del imgs, labels, teacher_outputs, student_outputs, ce_loss, mse_loss, total_loss\n",
    "                cleanup_memory()\n",
    "\n",
    "        avg_train_ce = ce_sum / len(train_loader)\n",
    "        avg_train_mse = mse_sum / len(train_loader)\n",
    "        avg_train_total = total_sum / len(train_loader)\n",
    "\n",
    "        # ==== VALIDATION ====\n",
    "        student.eval()\n",
    "        ce_sum, mse_sum, total_sum = 0.0, 0.0, 0.0\n",
    "        total, correct = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "                with autocast():\n",
    "                    teacher_outputs = teacher(imgs)\n",
    "                    student_outputs = student(imgs)\n",
    "\n",
    "                    # Calculate losses\n",
    "                    # Hard-label supervision\n",
    "                    ce_loss = F.cross_entropy(student_outputs, labels)\n",
    "                    \n",
    "                    # Soft-label supervision (teacher guidance)\n",
    "                    teacher_soft = F.softmax(teacher_outputs / temperature, dim=1)\n",
    "                    student_soft = F.softmax(student_outputs / temperature, dim=1)\n",
    "                    mse_loss = F.mse_loss(student_soft, teacher_soft) * (temperature ** 2)\n",
    "                    \n",
    "                    # Total loss (weighted)\n",
    "                    total_loss = alpha * mse_loss + (1 - alpha) * ce_loss\n",
    "                ce_sum += ce_loss.item()\n",
    "                mse_sum += mse_loss.item()\n",
    "                total_sum += total_loss.item()\n",
    "\n",
    "                _, preds = torch.max(student_outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += preds.eq(labels).sum().item()\n",
    "\n",
    "                del imgs, labels, teacher_outputs, student_outputs\n",
    "\n",
    "        avg_val_ce = ce_sum / len(val_loader)\n",
    "        avg_val_mse = mse_sum / len(val_loader)\n",
    "        avg_val_total = total_sum / len(val_loader)\n",
    "        val_acc = 100.0 * correct / total if total > 0 else 0.0\n",
    "\n",
    "        scheduler.step(avg_val_total)\n",
    "\n",
    "        # Store history\n",
    "        history['train_ce_loss'].append(avg_train_ce)\n",
    "        history['train_mse_loss'].append(avg_train_mse)\n",
    "        history['train_total_loss'].append(avg_train_total)\n",
    "        history['val_ce_loss'].append(avg_val_ce)\n",
    "        history['val_mse_loss'].append(avg_val_mse)\n",
    "        history['val_total_loss'].append(avg_val_total)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        if epoch % 1 == 0:  \n",
    "            print(f\"Epoch {epoch+1}/{epochs} \"\n",
    "                  f\"- Train CE: {avg_train_ce:.4f} MSE: {avg_train_mse:.4f} Total: {avg_train_total:.4f} \"\n",
    "                  f\"- Val CE: {avg_val_ce:.4f} MSE: {avg_val_mse:.4f} Total: {avg_val_total:.4f} \"\n",
    "                  f\"- Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(student.state_dict(), save_path)\n",
    "\n",
    "        cleanup_memory()\n",
    "\n",
    "    cleanup_memory()\n",
    "    return student, best_val_acc, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c3ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_student_as_tflite(student, example_input, output_path=\"student_model.tflite\"):\n",
    "    \"\"\"\n",
    "    Export a trained PyTorch model to TensorFlow Lite (.tflite)\n",
    "    without using ONNX or onnx-tf.\n",
    "    \"\"\"\n",
    "\n",
    "    student.eval()\n",
    "\n",
    "    traced_model = torch.jit.trace(student, example_input)\n",
    "    torchscript_path = \"student_model.pt\"\n",
    "    traced_model.save(torchscript_path)\n",
    "    print(f\"[INFO] TorchScript model saved to {torchscript_path}\")\n",
    "\n",
    "    class TorchModelWrapper(tf.Module):\n",
    "        def __init__(self, torch_model):\n",
    "            super().__init__()\n",
    "            self.torch_model = torch_model\n",
    "\n",
    "        @tf.function(input_signature=[tf.TensorSpec(shape=example_input.shape, dtype=tf.float32)])\n",
    "        def __call__(self, x):\n",
    "            x_torch = torch.from_numpy(x.numpy()).to(next(student.parameters()).device)\n",
    "            with torch.no_grad():\n",
    "                y_torch = self.torch_model(x_torch)\n",
    "            return tf.convert_to_tensor(y_torch.cpu().numpy(), dtype=tf.float32)\n",
    "\n",
    "    wrapper = TorchModelWrapper(student)\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_concrete_functions([wrapper.__call__.get_concrete_function()])\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Optional: enable quantization\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "    print(f\"TFLite model exported to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc7900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kd(save_tflite=True):\n",
    "    NUM_CLASSES = 6\n",
    "    seed = 3  # single run only\n",
    "\n",
    "    results = {\n",
    "        'test_acc': None,\n",
    "        'val_acc': None,\n",
    "        'train_ce_loss': None,\n",
    "        'train_mse_loss': None,\n",
    "        'train_total_loss': None,\n",
    "        'val_ce_loss': None,\n",
    "        'val_mse_loss': None,\n",
    "        'val_total_loss': None,\n",
    "        'classification_report': None,\n",
    "        'teacher_acc': None,\n",
    "        'confusion_matrix': None,\n",
    "        'y_true': None,\n",
    "        'y_pred': None\n",
    "    }\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"KNOWLEDGE DISTILLATION EXPERIMENT - SINGLE RUN\")\n",
    "    print(f\"Dataset size: Train={len(train_ds)}, Val={len(val_ds)}, Test={len(test_ds)}\")\n",
    "    print(f\"Classes: {train_ds.classes}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    set_seed(seed)\n",
    "    cleanup_memory()\n",
    "\n",
    "    # --- Teacher & Student Initialization ---\n",
    "    teacher = get_teacher(NUM_CLASSES, pretrained=True).to(device)\n",
    "    student = get_student(NUM_CLASSES, pretrained=True).to(device)\n",
    "\n",
    "    print_model_parameters(teacher, \"Teacher (ResNet50)\")\n",
    "    print_model_parameters(student, \"Student (MobileNetV2)\")\n",
    "\n",
    "    # --- Train Teacher ---\n",
    "    print(\"Finetuning teacher...\")\n",
    "    teacher, teacher_acc = finetune_teacher(\n",
    "        teacher, train_loader, val_loader, device, \n",
    "        epochs=100, lr=1e-4, save_path=f'./teacher_seed{seed}.pth'\n",
    "    )\n",
    "    print(f\"Teacher validation accuracy: {teacher_acc:.2f}%\")\n",
    "    results['teacher_acc'] = teacher_acc\n",
    "\n",
    "    # --- Train Student with KD ---\n",
    "    print(\"Starting knowledge distillation...\")\n",
    "    cleanup_memory()\n",
    "    student, best_val_acc, history = train_student_kd(\n",
    "        teacher, student, train_loader, val_loader, device,\n",
    "        epochs=100,\n",
    "        lr=1e-4, \n",
    "        alpha=0.7,\n",
    "        temperature=4.0,\n",
    "        save_path=f'./student_seed{seed}.pth'\n",
    "    )\n",
    "\n",
    "    results['val_acc'] = history['val_acc']\n",
    "    results['train_ce_loss'] = history['train_ce_loss']\n",
    "    results['train_mse_loss'] = history['train_mse_loss']\n",
    "    results['train_total_loss'] = history['train_total_loss']\n",
    "    results['val_ce_loss'] = history['val_ce_loss']\n",
    "    results['val_mse_loss'] = history['val_mse_loss']\n",
    "    results['val_total_loss'] = history['val_total_loss']\n",
    "\n",
    "    # --- Test Evaluation ---\n",
    "    print(\"Evaluating on test set...\")\n",
    "    student.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outs = student(imgs)\n",
    "            _, preds = torch.max(outs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            del imgs, labels, outs\n",
    "\n",
    "    test_acc = 100.0 * np.mean(np.array(y_true) == np.array(y_pred))\n",
    "    print(f\"Test accuracy: {test_acc:.2f}%\")\n",
    "    results['test_acc'] = test_acc\n",
    "    results['y_true'] = y_true\n",
    "    results['y_pred'] = y_pred\n",
    "\n",
    "    # --- Reports ---\n",
    "    report = classification_report(y_true, y_pred, target_names=train_ds.classes, output_dict=True, zero_division=0)\n",
    "    results['classification_report'] = report\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    results['confusion_matrix'] = cm\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_ds.classes)\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    plt.title(f'Confusion Matrix - Test Set (Acc: {test_acc:.2f}%)')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(results['val_acc'], color='blue', label='Validation Accuracy')\n",
    "    plt.title('Validation Accuracy Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # --- TFLite Export (No ONNX) ---\n",
    "    if save_tflite:\n",
    "        print(\"Converting student model to TFLite (no ONNX)...\")\n",
    "\n",
    "        class TorchModelWrapper(tf.Module):\n",
    "            def __init__(self, torch_model):\n",
    "                super().__init__()\n",
    "                self.torch_model = torch_model\n",
    "\n",
    "            @tf.function(input_signature=[tf.TensorSpec([1, 3, 224, 224], tf.float32)])\n",
    "            def __call__(self, x):\n",
    "                x_torch = torch.from_numpy(x.numpy()).to(device)\n",
    "                with torch.no_grad():\n",
    "                    y_torch = self.torch_model(x_torch)\n",
    "                return tf.convert_to_tensor(y_torch.cpu().numpy(), dtype=tf.float32)\n",
    "\n",
    "        dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "        wrapper = TorchModelWrapper(student.eval())\n",
    "        concrete_func = wrapper.__call__.get_concrete_function()\n",
    "\n",
    "        converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "        with open(\"student_model.tflite\", \"wb\") as f:\n",
    "            f.write(tflite_model)\n",
    "\n",
    "        print(\"✅ Student model saved as student_model.tflite (ONNX-free)\")\n",
    "\n",
    "    del teacher, student\n",
    "    cleanup_memory()\n",
    "    print(\"Run completed. Memory cleaned.\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03177df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method('spawn', force=True) \n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "    results = run_kd(save_tflite=True)\n",
    "    print(\"\\nExperiment completed.\")\n",
    "    print(f\"Final test accuracy: {results['test_acc']:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
